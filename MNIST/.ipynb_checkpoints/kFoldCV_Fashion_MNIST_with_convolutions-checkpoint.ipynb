{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b646b31-885d-47bf-bb35-2028aa3f6ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from scipy import stats as st\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "465a4ddd-62f2-4067-aa68-51bb743c2ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def h(x):\n",
    "    # Activation function, let's just use Relu\n",
    "    return np.maximum(0,x)\n",
    "\n",
    "def convolve(kernels, x_pixels, y_pixels, image_data, print_names = []):\n",
    "    x_pixels_convolved = x_pixels - kernels[0].shape[0] + 1 # new x pixels\n",
    "    y_pixels_convolved = y_pixels - kernels[0].shape[1] + 1 # new y pixels\n",
    "    channels_convolved = kernels.shape[0]                   # how many kernels and, hence, output channels\n",
    "\n",
    "    # of original image:\n",
    "    selected_image = image_data\n",
    "\n",
    "    if len(print_names) > 0:\n",
    "        image = Image.fromarray((selected_image).astype(np.uint8)).save(\"original.png\")\n",
    "\n",
    "    convolved_image = np.empty((channels_convolved,x_pixels_convolved,y_pixels_convolved))\n",
    "    # now let's cycle through each channel and apply appropriate kernels\n",
    "    for c in range(channels_convolved):\n",
    "        convolved_image_raw = scipy.signal.convolve2d(selected_image,kernels[c],mode='valid')\n",
    "            \n",
    "        for i in range(x_pixels_convolved):\n",
    "            for j in range(y_pixels_convolved):\n",
    "                convolved_image[c][i][j] = h(convolved_image_raw[i][j])  \n",
    "\n",
    "        if len(print_names) > 0:\n",
    "            cm = plt.get_cmap('bwr')\n",
    "            colored_image = cm(convolved_image[c]/255)\n",
    "            image = Image.fromarray((colored_image[:, :, :3] * 255).astype(np.uint8)).save(print_names[c])\n",
    "        \n",
    "    return convolved_image\n",
    "\n",
    "def max_pool(input_image, windowsize, print_names = []):\n",
    "    x_pixels = int(input_image[0].shape[0]/windowsize) # new x pixels\n",
    "    y_pixels = int(input_image[0].shape[1]/windowsize) # new y pixels\n",
    "    channels = int(input_image.shape[0])     # channels\n",
    "    \n",
    "    max_pooled_image = np.zeros((channels,x_pixels,y_pixels))\n",
    "    # now let's cycle through each channel and max pool\n",
    "    for c in range(channels):\n",
    "        for i in range(x_pixels):\n",
    "            for j in range(y_pixels):\n",
    "                sum = np.zeros((windowsize,windowsize))\n",
    "                for i2 in range(windowsize):\n",
    "                    for j2 in range(windowsize):\n",
    "                        sum[i2][j2] = input_image[c][windowsize*i + i2][windowsize*j + j2]\n",
    "                max_pooled_image[c][i][j] = np.max(sum)\n",
    "\n",
    "        if len(print_names) > 0:\n",
    "            cm = plt.get_cmap('bwr')\n",
    "            colored_image = cm(max_pooled_image[c]/255)\n",
    "            image = Image.fromarray((colored_image[:, :, :3] * 255).astype(np.uint8)).save(print_names[c])\n",
    "\n",
    "    return max_pooled_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "571032af-3afd-4d0a-9d7f-5bf37d790e65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 14:11:42.201825: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-24 14:11:45.143949: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-11-24 14:11:45.146493: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-11-24 14:11:45.464891: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-11-24 14:11:46.303448: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-24 14:11:46.381318: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-24 14:12:33.123441: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total data points, x pixels, y pixels, color channels\n",
      "(10000, 28, 28)\n",
      "(60000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "print(\"Total data points, x pixels, y pixels, color channels\")\n",
    "print(x_test.shape)\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc1f1546-d3bc-48e2-9e48-91e13933f4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's define some convolutions\n",
    "x_pixels = 28\n",
    "y_pixels = 28\n",
    "windowsize = 5\n",
    "number_of_kernels = 3\n",
    "kernels = np.empty((number_of_kernels,3,3))\n",
    "# first kernel\n",
    "kernels[0] = np.array([[-1, -2, -1],\n",
    "                         [0,0,0],\n",
    "                         [1, 2, 1]])\n",
    "# second kernel\n",
    "kernels[1] = np.array([[-1, 0, 1],\n",
    "                         [-2, 0, 2],\n",
    "                         [-1, 0, 1]])\n",
    "# third kernel\n",
    "kernels[2] = (1./9.) * np.array([[1, 1, 1],\n",
    "                         [1, 1, 1],\n",
    "                         [1, 1, 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "86ea5cd7-4416-4d91-83ef-cf6102c65971",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 5, 5)\n",
      "Starting testing data\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "4000\n",
      "4100\n",
      "4200\n",
      "4300\n",
      "4400\n",
      "4500\n",
      "4600\n",
      "4700\n",
      "4800\n",
      "4900\n",
      "5000\n",
      "5100\n",
      "5200\n",
      "5300\n",
      "5400\n",
      "5500\n",
      "5600\n",
      "5700\n",
      "5800\n",
      "5900\n",
      "6000\n",
      "6100\n",
      "6200\n",
      "6300\n",
      "6400\n",
      "6500\n",
      "6600\n",
      "6700\n",
      "6800\n",
      "6900\n",
      "7000\n",
      "7100\n",
      "7200\n",
      "7300\n",
      "7400\n",
      "7500\n",
      "7600\n",
      "7700\n",
      "7800\n",
      "7900\n",
      "8000\n",
      "8100\n",
      "8200\n",
      "8300\n",
      "8400\n",
      "8500\n",
      "8600\n",
      "8700\n",
      "8800\n",
      "8900\n",
      "9000\n",
      "9100\n",
      "9200\n",
      "9300\n",
      "9400\n",
      "9500\n",
      "9600\n",
      "9700\n",
      "9800\n",
      "9900\n",
      "Starting training data\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "4000\n",
      "4100\n",
      "4200\n",
      "4300\n",
      "4400\n",
      "4500\n",
      "4600\n",
      "4700\n",
      "4800\n",
      "4900\n",
      "5000\n",
      "5100\n",
      "5200\n",
      "5300\n",
      "5400\n",
      "5500\n",
      "5600\n",
      "5700\n",
      "5800\n",
      "5900\n",
      "6000\n",
      "6100\n",
      "6200\n",
      "6300\n",
      "6400\n",
      "6500\n",
      "6600\n",
      "6700\n",
      "6800\n",
      "6900\n",
      "7000\n",
      "7100\n",
      "7200\n",
      "7300\n",
      "7400\n",
      "7500\n",
      "7600\n",
      "7700\n",
      "7800\n",
      "7900\n",
      "8000\n",
      "8100\n",
      "8200\n",
      "8300\n",
      "8400\n",
      "8500\n",
      "8600\n",
      "8700\n",
      "8800\n",
      "8900\n",
      "9000\n",
      "9100\n",
      "9200\n",
      "9300\n",
      "9400\n",
      "9500\n",
      "9600\n",
      "9700\n",
      "9800\n",
      "9900\n",
      "10000\n",
      "10100\n",
      "10200\n",
      "10300\n",
      "10400\n",
      "10500\n",
      "10600\n",
      "10700\n",
      "10800\n",
      "10900\n",
      "11000\n",
      "11100\n",
      "11200\n",
      "11300\n",
      "11400\n",
      "11500\n",
      "11600\n",
      "11700\n",
      "11800\n",
      "11900\n",
      "12000\n",
      "12100\n",
      "12200\n",
      "12300\n",
      "12400\n",
      "12500\n",
      "12600\n",
      "12700\n",
      "12800\n",
      "12900\n",
      "13000\n",
      "13100\n",
      "13200\n",
      "13300\n",
      "13400\n",
      "13500\n",
      "13600\n",
      "13700\n",
      "13800\n",
      "13900\n",
      "14000\n",
      "14100\n",
      "14200\n",
      "14300\n",
      "14400\n",
      "14500\n",
      "14600\n",
      "14700\n",
      "14800\n",
      "14900\n",
      "15000\n",
      "15100\n",
      "15200\n",
      "15300\n",
      "15400\n",
      "15500\n",
      "15600\n",
      "15700\n",
      "15800\n",
      "15900\n",
      "16000\n",
      "16100\n",
      "16200\n",
      "16300\n",
      "16400\n",
      "16500\n",
      "16600\n",
      "16700\n",
      "16800\n",
      "16900\n",
      "17000\n",
      "17100\n",
      "17200\n",
      "17300\n",
      "17400\n",
      "17500\n",
      "17600\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 17\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;241m==\u001b[39m\u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     16\u001b[0m         \u001b[38;5;28mprint\u001b[39m(i)\n\u001b[0;32m---> 17\u001b[0m     convolved_image \u001b[38;5;241m=\u001b[39m \u001b[43mconvolve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkernels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_pixels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pixels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m     x_train_new[i] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mravel(max_pool(convolved_image, windowsize))\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAfter convolutions:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[2], line 23\u001b[0m, in \u001b[0;36mconvolve\u001b[0;34m(kernels, x_pixels, y_pixels, image_data, print_names)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(x_pixels_convolved):\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(y_pixels_convolved):\n\u001b[0;32m---> 23\u001b[0m         convolved_image[c][i][j] \u001b[38;5;241m=\u001b[39m \u001b[43mh\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvolved_image_raw\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m  \n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(print_names) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     26\u001b[0m     cm \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39mget_cmap(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbwr\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[2], line 3\u001b[0m, in \u001b[0;36mh\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mh\u001b[39m(x):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;66;03m# Activation function, let's just use Relu\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmaximum\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "new_size = (max_pool(convolve(kernels, x_pixels, y_pixels, x_train[0]), windowsize).shape)\n",
    "print(new_size)\n",
    "\n",
    "x_train_new = np.empty((x_train.shape[0],(new_size[0]*new_size[1]*new_size[2])))\n",
    "x_test_new = np.empty((x_test.shape[0],(new_size[0]*new_size[1]*new_size[2])))\n",
    "\n",
    "print(\"Starting testing data\")\n",
    "for i in range(len(x_test)):\n",
    "    if i % 100 ==0:\n",
    "        print(i)\n",
    "    convolved_image = convolve(kernels, x_pixels, y_pixels, x_test[i])\n",
    "    x_test_new[i] = np.ravel(max_pool(convolved_image, windowsize))\n",
    "print(\"Starting training data\")\n",
    "for i in range(len(x_train)):\n",
    "    if i % 100 ==0:\n",
    "        print(i)\n",
    "    convolved_image = convolve(kernels, x_pixels, y_pixels, x_train[i])\n",
    "    x_train_new[i] = np.ravel(max_pool(convolved_image, windowsize))\n",
    "\n",
    "print(\"After convolutions:\")\n",
    "print(x_train_new.shape)\n",
    "print(x_test_new.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4a581f4c-e709-4736-b01c-523971b922d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's define the folds\n",
    "n_folds = 5\n",
    "size_folds = int(x_train_new.shape[0]/n_folds)\n",
    "x_folds = np.empty((n_folds,size_folds,x_train_new.shape[1]))\n",
    "y_folds = np.empty((n_folds,size_folds))\n",
    "\n",
    "for i in range(n_folds):\n",
    "    x_folds[i] = x_train_new[size_folds*i:size_folds*(i+1)]\n",
    "    y_folds[i] = y_train[size_folds*i:size_folds*(i+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "96921be8-228a-4012-814e-c96ea229c328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start\n",
      "k value of 1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[67], line 30\u001b[0m\n\u001b[1;32m     28\u001b[0m model \u001b[38;5;241m=\u001b[39m NearestNeighbors(n_neighbors\u001b[38;5;241m=\u001b[39mk)\n\u001b[1;32m     29\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(x_fold_training,y_fold_training)\n\u001b[0;32m---> 30\u001b[0m test_neighbors \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkneighbors_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_fold_testing\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# test_nearest_neighbors looks through test_neighbors and gets the classifications of the k nearest ones\u001b[39;00m\n\u001b[1;32m     33\u001b[0m test_nearest_neighbors \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty((y_fold_testing\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m],k))\n",
      "File \u001b[0;32m/lustre/work/client/users/jwange/.conda/envs/datascience/lib/python3.11/site-packages/sklearn/neighbors/_base.py:981\u001b[0m, in \u001b[0;36mKNeighborsMixin.kneighbors_graph\u001b[0;34m(self, X, n_neighbors, mode)\u001b[0m\n\u001b[1;32m    977\u001b[0m \u001b[38;5;66;03m# check the input only in self.kneighbors\u001b[39;00m\n\u001b[1;32m    978\u001b[0m \n\u001b[1;32m    979\u001b[0m \u001b[38;5;66;03m# construct CSR matrix representation of the k-NN graph\u001b[39;00m\n\u001b[1;32m    980\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconnectivity\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 981\u001b[0m     A_ind \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkneighbors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_neighbors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_distance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    982\u001b[0m     n_queries \u001b[38;5;241m=\u001b[39m A_ind\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    983\u001b[0m     A_data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mones(n_queries \u001b[38;5;241m*\u001b[39m n_neighbors)\n",
      "File \u001b[0;32m/lustre/work/client/users/jwange/.conda/envs/datascience/lib/python3.11/site-packages/sklearn/neighbors/_base.py:822\u001b[0m, in \u001b[0;36mKNeighborsMixin.kneighbors\u001b[0;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[1;32m    815\u001b[0m use_pairwise_distances_reductions \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    816\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbrute\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    817\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m ArgKmin\u001b[38;5;241m.\u001b[39mis_usable_for(\n\u001b[1;32m    818\u001b[0m         X \u001b[38;5;28;01mif\u001b[39;00m X \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meffective_metric_\n\u001b[1;32m    819\u001b[0m     )\n\u001b[1;32m    820\u001b[0m )\n\u001b[1;32m    821\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_pairwise_distances_reductions:\n\u001b[0;32m--> 822\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mArgKmin\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    823\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    824\u001b[0m \u001b[43m        \u001b[49m\u001b[43mY\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_X\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    825\u001b[0m \u001b[43m        \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_neighbors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meffective_metric_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetric_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meffective_metric_params_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    828\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstrategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mauto\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    829\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_distance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_distance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    830\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m (\n\u001b[1;32m    833\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbrute\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetric \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprecomputed\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m issparse(X)\n\u001b[1;32m    834\u001b[0m ):\n\u001b[1;32m    835\u001b[0m     results \u001b[38;5;241m=\u001b[39m _kneighbors_from_graph(\n\u001b[1;32m    836\u001b[0m         X, n_neighbors\u001b[38;5;241m=\u001b[39mn_neighbors, return_distance\u001b[38;5;241m=\u001b[39mreturn_distance\n\u001b[1;32m    837\u001b[0m     )\n",
      "File \u001b[0;32m/lustre/work/client/users/jwange/.conda/envs/datascience/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py:258\u001b[0m, in \u001b[0;36mArgKmin.compute\u001b[0;34m(cls, X, Y, k, metric, chunk_size, metric_kwargs, strategy, return_distance)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Compute the argkmin reduction.\u001b[39;00m\n\u001b[1;32m    178\u001b[0m \n\u001b[1;32m    179\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;124;03mreturns.\u001b[39;00m\n\u001b[1;32m    256\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    257\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m X\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m Y\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mfloat64:\n\u001b[0;32m--> 258\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mArgKmin64\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    260\u001b[0m \u001b[43m        \u001b[49m\u001b[43mY\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    261\u001b[0m \u001b[43m        \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    262\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    263\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunk_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    264\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetric_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    265\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstrategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    266\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_distance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_distance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m X\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m Y\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mfloat32:\n\u001b[1;32m    270\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ArgKmin32\u001b[38;5;241m.\u001b[39mcompute(\n\u001b[1;32m    271\u001b[0m         X\u001b[38;5;241m=\u001b[39mX,\n\u001b[1;32m    272\u001b[0m         Y\u001b[38;5;241m=\u001b[39mY,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    278\u001b[0m         return_distance\u001b[38;5;241m=\u001b[39mreturn_distance,\n\u001b[1;32m    279\u001b[0m     )\n",
      "File \u001b[0;32msklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx:90\u001b[0m, in \u001b[0;36msklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/lustre/work/client/users/jwange/.conda/envs/datascience/lib/python3.11/site-packages/threadpoolctl.py:440\u001b[0m, in \u001b[0;36m_ThreadpoolLimiter.__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__enter__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    438\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[0;32m--> 440\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mtype\u001b[39m, value, traceback):\n\u001b[1;32m    441\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrestore_original_limits()\n\u001b[1;32m    443\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    444\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrap\u001b[39m(\u001b[38;5;28mcls\u001b[39m, controller, \u001b[38;5;241m*\u001b[39m, limits\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, user_api\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"Start\") # k Fold Cross Validation\n",
    "k_vals = [1,2,3,4,5,6,7,8,9,10,12,14,16,18,20,25,50,75,100]\n",
    "cv_error_vals = np.zeros((len(k_vals)))\n",
    "\n",
    "x_fold_training = np.empty((size_folds*(n_folds-1),x_train_new.shape[1]))\n",
    "y_fold_training = np.empty((size_folds*(n_folds-1)))\n",
    "x_fold_testing = np.empty((size_folds,x_train_new.shape[1]))\n",
    "y_fold_testing = np.empty((size_folds))\n",
    "\n",
    "# kNN\n",
    "for i in range(len(k_vals)):\n",
    "    k = k_vals[i]\n",
    "    print(\"k value of \" + str(k))\n",
    "    \n",
    "    for j in range(n_folds):\n",
    "\n",
    "        # let's set up training and testing data\n",
    "        s = 0\n",
    "        for k in range(n_folds):\n",
    "            if j==k:\n",
    "                x_fold_testing = x_folds[k]\n",
    "                y_fold_testing = y_folds[k]\n",
    "            else:\n",
    "                x_fold_training[size_folds*s:size_folds*(s+1)] = x_folds[k]\n",
    "                y_fold_training[size_folds*s:size_folds*(s+1)] = y_folds[k]\n",
    "                s += 1\n",
    "\n",
    "        model = NearestNeighbors(n_neighbors=k)\n",
    "        model.fit(x_fold_training,y_fold_training)\n",
    "        test_neighbors = model.kneighbors_graph(x_fold_testing)\n",
    "        \n",
    "        # test_nearest_neighbors looks through test_neighbors and gets the classifications of the k nearest ones\n",
    "        test_nearest_neighbors = np.empty((y_fold_testing.shape[0],k))\n",
    "        # y_pred gets the mode of the nearest neighbors\n",
    "        y_pred = np.empty((y_fold_testing.shape[0],1))\n",
    "        \n",
    "        print(\"Total number of test points: \" + str(x_fold_testing.shape[0]))\n",
    "        for i in range(x_test_new.shape[0]):\n",
    "            if i%100 == 0:\n",
    "                print(\"i=\" + str(i))\n",
    "            test_nearest_neighbors[i] = y_fold_training[np.nonzero(test_neighbors.toarray()[i])].reshape((k))\n",
    "            y_pred[i] = int(st.mode(test_nearest_neighbors[i], keepdims=True).mode)\n",
    "        \n",
    "        conf_matrix = confusion_matrix(y_fold_testing, y_pred)\n",
    "        print(\"k error:\" + str(1 - conf_matrix.trace()/conf_matrix.sum()))\n",
    "        cv_error_vals[i] += (1 - conf_matrix.trace()/conf_matrix.sum())/n_folds\n",
    "\n",
    "print(k_vals)\n",
    "print(cv_error_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c4d2ab-00ef-40cf-993a-ade88c319e1a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
